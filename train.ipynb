{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim import Optimizer\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGBLabel2LabelName = {\n",
    "    (128, 128, 128): \"Sky\",\n",
    "    (0, 128, 64): \"Building\",\n",
    "    (128, 0, 0): \"Building\",\n",
    "    (64, 192, 0): \"Building\",\n",
    "    (64, 0, 64): \"Building\",\n",
    "    (192, 0, 128): \"Building\",\n",
    "    (192, 192, 128): \"Pole\",\n",
    "    (0, 0, 64): \"Pole\",\n",
    "    (128, 64, 128): \"Road\",\n",
    "    (128, 0, 192): \"Road\",\n",
    "    (192, 0, 64): \"Road\",\n",
    "    (0, 0, 192): \"Sidewalk\",\n",
    "    (64, 192, 128): \"Sidewalk\",\n",
    "    (128, 128, 192): \"Sidewalk\",\n",
    "    (128, 128, 0): \"Tree\",\n",
    "    (192, 192, 0): \"Tree\",\n",
    "    (192, 128, 128): \"SignSymbol\",\n",
    "    (128, 128, 64): \"SignSymbol\",\n",
    "    (0, 64, 64): \"SignSymbol\",\n",
    "    (64, 64, 128): \"Fence\",\n",
    "    (64, 0, 128): \"Car\",\n",
    "    (64, 128, 192): \"Car\",\n",
    "    (192, 128, 192): \"Car\",\n",
    "    (192, 64, 128): \"Car\",\n",
    "    (128, 64, 64): \"Car\",\n",
    "    (64, 64, 0): \"Pedestrian\",\n",
    "    (192, 128, 64): \"Pedestrian\",\n",
    "    (64, 0, 192): \"Pedestrian\",\n",
    "    (64, 128, 64): \"Pedestrian\",\n",
    "    (0, 128, 192): \"Bicyclist\",\n",
    "    (192, 0, 192): \"Bicyclist\",\n",
    "    (0, 0, 0): \"Void\",\n",
    "}\n",
    "\n",
    "LabelName2LabelIndex = {\n",
    "    \"Sky\": 0,\n",
    "    \"Building\": 1,\n",
    "    \"Pole\": 2,\n",
    "    \"Road\": 3,\n",
    "    \"Sidewalk\": 4,\n",
    "    \"Tree\": 5,\n",
    "    \"SignSymbol\": 6,\n",
    "    \"Fence\": 7,\n",
    "    \"Car\": 8,\n",
    "    \"Pedestrian\": 9,\n",
    "    \"Bicyclist\": 10,\n",
    "    \"Void\": 11,\n",
    "}\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_root: str, mask_root):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_paths = sorted(glob(f\"{image_root}/*.png\"))\n",
    "        self.gt_paths = sorted(glob(f\"{mask_root}/*.png\"))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # load data\n",
    "        image = np.array(Image.open(self.image_paths[index]).convert(\"RGB\"))\n",
    "        gt_mask = np.array(Image.open(self.gt_paths[index]))\n",
    "        gt_mask = gt_mask / (0.039 * 25)\n",
    "\n",
    "        # transform data\n",
    "        transforms_img = T.Compose(\n",
    "            [\n",
    "                T.ToTensor(),\n",
    "                T.RandomCrop(224),\n",
    "                T.RandomHorizontalFlip(p=0.3),\n",
    "                T.ConvertImageDtype(torch.float),\n",
    "                T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "        transforms_gt = T.Compose(\n",
    "            [\n",
    "                T.ToTensor(),\n",
    "                T.RandomCrop(224),\n",
    "                T.RandomHorizontalFlip(p=0.3),\n",
    "            ]\n",
    "        )\n",
    "        image, gt_mask = transforms_img(image), transforms_gt(gt_mask)\n",
    "        return image, gt_mask.squeeze().long()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, stride=2, padding=1)\n",
    "            if down\n",
    "            else nn.ConvTranspose2d(in_channels, out_channels, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, features: int = 64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.initial_down = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.down1 = Block(features, features * 2, down=True)\n",
    "        self.down2 = Block(features * 2, features * 4, down=True)\n",
    "        self.down3 = Block(features * 4, features * 8, down=True)\n",
    "\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(features * 8, features * 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(features * 16, features * 8, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.up1 = Block(features * 8 * 2, features * 4, down=False)\n",
    "        self.up2 = Block(features * 4 * 2, features * 2, down=False)\n",
    "        self.up3 = Block(features * 2 * 2, features, down=False)\n",
    "\n",
    "        self.final_up = nn.Sequential(nn.ConvTranspose2d(features * 2, out_channels, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.initial_down(x)\n",
    "        d2 = self.down1(d1)\n",
    "        d3 = self.down2(d2)\n",
    "        d4 = self.down3(d3)\n",
    "        bottleneck = self.bottleneck(d4)\n",
    "        up1 = self.up1(torch.cat([bottleneck, d4], 1))\n",
    "        up2 = self.up2(torch.cat([up1, d3], 1))\n",
    "        up3 = self.up3(torch.cat([up2, d2], 1))\n",
    "        out = self.final_up(torch.cat([up3, d1], 1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_epoch(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    loss_fn: CrossEntropyLoss,\n",
    "    epoch: int,\n",
    "    optimizer: Optimizer = None,\n",
    "    train: bool = True,\n",
    "):\n",
    "    running_loss = 0\n",
    "    pbar = tqdm(dataloader)\n",
    "    for i, data in enumerate(pbar):\n",
    "        pbar.set_description(f\"[Epoch {str(epoch+1).zfill(3)}]: \")\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        images, gts = data\n",
    "        images = images.to(device).double()\n",
    "        gts.to(device)\n",
    "\n",
    "        # zero gradients\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # pass data through model\n",
    "        preds = model(images)\n",
    "        loss = loss_fn(preds, gts)\n",
    "        loss.backward()\n",
    "\n",
    "        # adjust weights\n",
    "        if train:\n",
    "            optimizer.step()\n",
    "\n",
    "        # update progress bar\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 4:\n",
    "            last_loss = running_loss / 5\n",
    "            pbar.postfix(f\"loss: {last_loss}\")\n",
    "            running_loss = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine hyper params\n",
    "batch_size = 8\n",
    "max_epochs = 20\n",
    "lr = 0.0001\n",
    "betas = (0.9, 0.999)\n",
    "num_classes = 12\n",
    "\n",
    "loss = CrossEntropyLoss()\n",
    "model = UNet(3, num_classes).double()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=betas)\n",
    "train_dataset = CustomDataset(\n",
    "    image_root=\"/home/jonas/Downloads/CamVid/train\",\n",
    "    mask_root=\"/home/jonas/Downloads/CamVid/trainannot\",\n",
    ")\n",
    "val_dataset = CustomDataset(\n",
    "    image_root=\"/home/jonas/Documents/data/CamVid/val\",\n",
    "    mask_root=\"/home/jonas/Documents/data/CamVid/valannot\",\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size, shuffle=True, num_workers=4\n",
    ")\n",
    "val_dataloader = DataLoader(val_dataset, batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    train_val_epoch(model, train_dataloader, loss, epoch, optimizer, train=True)\n",
    "    train_val_epoch(model, val_dataloader, loss, epoch, train=False)\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
